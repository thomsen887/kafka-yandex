package filter

import (
	"context"
	"encoding/json"
	"log"
	"regexp"
	"strings"

	"github.com/lovoo/goka"
)

// --- –¢–∏–ø—ã —Å–æ–æ–±—â–µ–Ω–∏–π ---

type Message struct {
	SenderID    string
	RecipientID string
	Content     string
}

type MessageCodec struct{}

func (c *MessageCodec) Encode(value any) ([]byte, error) { return json.Marshal(value) }
func (c *MessageCodec) Decode(data []byte) (any, error) {
	var m Message
	err := json.Unmarshal(data, &m)
	return &m, err
}

// --- –û–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤ ---

type WordUpdate struct {
	Word   string
	Active bool
}

type WordUpdateCodec struct{}

func (c *WordUpdateCodec) Encode(value any) ([]byte, error) { return json.Marshal(value) }
func (c *WordUpdateCodec) Decode(data []byte) (any, error) {
	var wu WordUpdate
	err := json.Unmarshal(data, &wu)
	return &wu, err
}

// --- –¢–∞–±–ª–∏—Ü–∞ –±–∞–Ω–æ–≤ ---

type BannedWords struct {
	Words map[string]bool
}

type BannedWordsCodec struct{}

func (c *BannedWordsCodec) Encode(value any) ([]byte, error) { return json.Marshal(value) }
func (c *BannedWordsCodec) Decode(data []byte) (any, error) {
	var bw BannedWords
	err := json.Unmarshal(data, &bw)
	return &bw, err
}

// --- –ê–≥—Ä–µ–≥–∞—Ç–æ—Ä –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã—Ö —Å–ª–æ–≤ ---
func RunBanAggregatorProcessor(brokers []string, topic goka.Stream) {
	group := goka.Group("pr3_banned_words") // üëà –∏–º—è –≥—Ä—É–ø–ø—ã –∏ —Ç–∞–±–ª–∏—Ü—ã

	g := goka.DefineGroup(group,
		goka.Input(topic, new(WordUpdateCodec), func(ctx goka.Context, msg any) {
			
            update := msg.(*WordUpdate)

			var state *BannedWords
			if val := ctx.Value(); val != nil {
				state = val.(*BannedWords)
			} else {
				state = &BannedWords{Words: make(map[string]bool)}
			}

			state.Words[strings.ToLower(update.Word)] = update.Active 
			ctx.SetValue(state)

			if update.Active {
				log.Printf("[banagg] ‚úÖ '%s' –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –±–∞–Ω", update.Word)
			} else {
				log.Printf("[banagg] ‚ùå '%s' —É–¥–∞–ª–µ–Ω–æ –∏–∑ –±–∞–Ω–∞", update.Word)
			}
		}),
		goka.Persist(new(BannedWordsCodec)), 
	)

	p, err := goka.NewProcessor(brokers, g)
	if err != nil {
		log.Fatal(err)
	}
	if err := p.Run(context.Background()); err != nil {
		log.Fatal(err)
	}
    
}


func RunFilterProcessor(brokers []string, input goka.Stream, output goka.Stream) {
	group := goka.Group("pr3_banwriter")

	log.Println("[filter] üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Lookup")

	g := goka.DefineGroup(group,
		goka.Input(input, new(MessageCodec), func(ctx goka.Context, msg any) {
			m := msg.(*Message)
			log.Printf("[filter] üì• –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç %s: %s", m.SenderID, m.Content)

			val := ctx.Lookup(goka.GroupTable("pr3_banned_words"), "system")
			if val == nil {
				log.Println("[filter] ‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
				ctx.Emit(output, m.RecipientID, m)
				return
			}

			bw := val.(*BannedWords)
			if bw == nil || len(bw.Words) == 0 {
				log.Println("[filter] üì≠ –¢–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
				ctx.Emit(output, m.RecipientID, m)
				return
			}

	

			replaced := m.Content
			censored := false
			for word := range bw.Words {
				if bw.Words[word] {
					re := regexp.MustCompile(`(?i)` + regexp.QuoteMeta(word))
					if re.MatchString(replaced) {
						replaced = re.ReplaceAllString(replaced, "***")
						censored = true
					}
				}
			}

			if censored {
				log.Printf("[filter] üö´ –ù–∞–π–¥–µ–Ω—ã –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ ‚Äî —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–æ: %s", replaced)
				m.Content = replaced
			} else {
				log.Println("[filter] ‚úÖ –ù–µ—Ç –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã—Ö —Å–ª–æ–≤ ‚Äî —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Å—Ç–∞–≤–ª–µ–Ω–æ –∫–∞–∫ –µ—Å—Ç—å")
			}

			ctx.Emit(output, m.RecipientID, m)
		}),
		goka.Lookup(goka.GroupTable("pr3_banned_words"), new(BannedWordsCodec)), 
		goka.Output(output, new(MessageCodec)), 
	)

	p, err := goka.NewProcessor(brokers, g)
	if err != nil {
		log.Fatal(err)
	}
	if err := p.Run(context.Background()); err != nil {
		log.Fatal(err)
	}
}






